{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aedd003-be0d-43b1-8691-04a45bc29700",
   "metadata": {},
   "source": [
    "# TITLE: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94b7d83-8454-4bc7-a8da-2e63cb39adff",
   "metadata": {},
   "source": [
    "## TO DO LIST:\n",
    "1. updated the github and change the read_CSV to link\n",
    "2. explain the questions since the original data set quite large\n",
    "3. results and discussion\n",
    "4. Methodlogy 5.3\n",
    "5. Reference\n",
    "6. Layout: directory index??? if possible\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60871ed2-a808-4693-bd1e-d4aac0bc70f2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. INTRODUCTION\n",
    "The research aims to explore the factors that affect the daily demand for bike-sharing ridership in New York (NYC) before and after the COVID-19 pandemic. It will adopt machine learning methods to predict the daily ridership demand, which can reflect the impact of these factors. The COVID-19 pandemic has significantly changed travel mode choices, and bike-sharing systems (BSS) as travel modes to replace public transport (PT) and maintain social distance have been promoted (Teixeira, Silva and Moura E Sá, 2021). During the pandemic, BSS in Seoul and London reported a growth trend for ridership (Li et al., 2021; Goh, Choi and Song, 2023). Furthermore, the studies revealed that the usage pattern of BSS has shifted from being a supplementary mode for PT before the pandemic to an alternative for short-term trips of PT (Kim and Cho, 2022; Ma et al., 2019; Ashraf et al., 2021). Thus, investigating the factors that affect the demand for BSS before and after the pandemic and exploring the changes between them will help contribute to further improving the supply of BSS. \n",
    "\n",
    "Citi Bike, the BSS in NYC, experienced a period during the pandemic when ridership declined and then gradually recovered (Wang and Noland, 2021). Subsequently, Citi Bike’s ridership continued to rise. In December 2021, it reported an average of 54,787 rides per day, showing a 74% increase compared to December 2019 (Lyft, 2020; Lyft, 2021). Since there are significant differences in ridership before and after the pandemic, the study will adopt Citi Bike data for 2019 and 2020 issued by Lyft to analyse the influence of weather, usage patterns and customer attributes on the Citi Bike ridership in the two periods.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7448a7b5-45db-403d-b025-ea0fb4c6f78a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. LITERATURE REVIEW\n",
    "\n",
    "**The Factors Influencing the BSS Trip before and during/after the Pandemic**\n",
    "\n",
    "Before the pandemic, the motivating and inhibiting factors influencing BSS trip demand have been discussed in diverse aspects, mainly focusing on weather conditions, travel patterns, and customer attributes. Furthermore, previous studies have exposed the changes in BSS demand before and during/after the pandemic. \n",
    "\n",
    "**Weather Conditions**\n",
    "\n",
    "Weather conditions display differential impacts on BSS demand in different cases. It is proved that temperature increases positively affect the BSS demand (El-Assi, Mahmoud and Habib, 2017). However, by modelling BSS demand in Daejeon, South Korea, in 2015, Kim (2018) stated that a daily temperature above 30°C would decrease BSS demand. Besides, some studies reported that precipitation and wind speed have a negative relationship with BSS demand (Kim, 2017; Chibwe et al., 2021). However, in their study of modelling BSS trip data collected from 2013 to 2015 in San Francisco Bay Area, Ashqar, Elhenawy, and Rakha (2019) found that precipitation was not a significant predictor, possibly due to the relatively small precipitation types in the area. Thus, it is essential to examine the influence of weather conditions on BSS demand in NYC since weather conditions have varying degrees of importance across different geographic areas. \n",
    "\n",
    "**Travel Patterns**\n",
    "\n",
    "Trip duration and calendar attributes are employed to describe the impact of travel patterns on BSS demand. In the study of Toronto BSS in 2013, El-Assi, Mahmoud, and Habib (2017) reported that trip distance is negatively correlated to travel trips. Thus, shorter travel times are an important factor driving BSS demand in the Netherlands (Engbers and Hendriksen, 2010). However, in their study of three US cities during the pandemic, Padmanabhan et al.(2021) revealed that although BSS trips decreased, the average travel time increased. \n",
    "\n",
    "In addition, some studies have discussed the calendar impacts on BSS demand. Chibwe et al. (2021) revealed that weekends in London had lower BSS demand than weekdays, dropping by 17.4%. In contrast, Corcoran et al.(2014) indicated that weekends are positively associated with BSS usage in Brisbane, Australia. Moreover, the study by Kim (2018) did not find a difference in BSS demand between weekdays and weekends. Thus, calendar impacts on BSS demand still need to be further studied.\n",
    "\n",
    "\n",
    "**User Attributes** \n",
    "\n",
    "Regarding customer attributes, gender and user type have been discussed as factors influencing BSS demand and have reflected significant changes before and after the pandemic. Females reported less demand for BSS than males in Texas in 2019(Blazanin et al., 2022). This gender difference in demand was demonstrated in pre-pandemic New York, where female members contributed less BSS demand (Reilly, Wang and Crossa, 2022). However, Uddin, Hwang and Hasine (2023) examined the BSS demand in NYC before and during the pandemic, revealing an opposite trend: female users demonstrated greater BSS demand than males during the pandemic. \n",
    "\n",
    "In addition, Marleau, Lee and Geneidy (2012) studied the impact of user types on BSS demand in Montreal, Canada, and stated that member users contributed more to increasing travel trips. On the contrary, Jia et al.(2023) revealed that, in Washington D.C., although BSS trips made by member users decreased during the pandemic, the trips made by casual users increased by 40% since the policy encouraged the shift of travel mode to BSS. Therefore, it is necessary to examine the impact of these variables on BSS demand after changes have occurred, providing insights into the management and supply of BSS. \n",
    "\n",
    "**The Machine Learning Techniques for Predicting BSS Demand** \n",
    "\n",
    "Previous research has explored applying various machine learning techniques to predict BSS demand. Studies by Feng and Wang (2017), and V. E. and Cho (2024) demonstrated the effectiveness of Random Forest (RF) in this topic, attributing its advantages to ensemble learning systems that combine different decision trees to enhance accuracy and mitigate overfitting (Li and Axhausen, 2019). Meanwhile, XGBoost (eXtreme Gradient Boosting), another ensemble learning for gradient boosting, has emerged as a promising approach for the prediction (Hu et al., 2022; Uddin, Hwang, & Hasnine, 2023). Notably, Lainjo (2020) reported higher accuracy of XGBoost compared to RF. Thus, this research aims to examine further and compare the performance of RF and XGBoost in predicting BSS demand."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b2e973a-c60b-44a0-b4fc-6b09418db89e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3. RESEARCH QUESTION\n",
    "\n",
    "Before COVID-19, BSS riderships were influenced by weather, travel patterns, and user attributes. However, the changes after COVID-19 still require analysis. Thus, the research questions are:\n",
    "\n",
    "How can machine learning methods, particularly Random Forest and XGBoost, be effectively utilised to predict daily BSS demand?\n",
    "\n",
    "Which variables reflect the relative importance of predicting BSS demand compared to before and after COVID-19?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "481473b6-eaa2-4ee1-8ca9-0331ef5b2ba2",
   "metadata": {},
   "source": [
    "## 4. PRESENTATION OF DATA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f8fd36-2783-49e8-a4c9-d03162c138c2",
   "metadata": {},
   "source": [
    "\n",
    "Table 1 The list of variables\n",
    "|Aspects|Variable Name|Definition|Unit|Note|\n",
    "|:---|:---|:---|:--|:--|\n",
    "|Dependent variable| Daily BSS Trip(Before)| Daily BSS trip from September 2019 to February 2020|Count||\n",
    "||Daily Bike Trip(After)|Daily BSS trip from June 2020 to December 2020|Count||\n",
    "|Weather Conditions|Average Temperature|Average temperature for the day|Fahrenheit(F)||\n",
    "||Heating Degree Days (HDD) |The degrees of cold conditions (Lower than 65F) |Fahrenheit(F)||\n",
    "||Cooling Degree Days (CDD)|The degrees of hot conditions (Higher than 65F) |Fahrenheit(F)||\n",
    "||Total Liquid Content (TLC)|The water equivalent number of precipitation for the day|Inches(in)||\n",
    "||Average Wind Speed|Daily average wind speed |Miles per hour||\n",
    "|Travel Pattern| The Proportion of Trip Duration (within 15mins)|The Proportion of trip duration within 15mins for the day|%||\n",
    "||The Proportion of Trip Duration (15-30mins)|The Proportion of trip duration between 15 to 30mins for the day|%||\n",
    "||The Proportion of Trip Duration (above 30mins)|The Proportion of trip duration above 30 mins for the day|%||\n",
    "||Day Type|The distinguish of weekday (1) and weekend (0) |/||\n",
    "|User Attributes|Gender|The proportion of female and male users|%||\n",
    "|| User Types|The proportion of customer(4-hour pass or 3-day pass user)|%||\n",
    "|||The proportion of customer and subscriber(Annual Member)|%||\n",
    "\n",
    "\n",
    "Table 2 The Extreme Weather Events (Source from [National Weather Service(2024)](https://www.weather.gov/okx/stormevents))\n",
    "|Period|Date|Event|\n",
    "|:---|:---|:---|\n",
    "|Before COVID_19(Sep2019 to Feb 2020)| 2019-12-18| Snow Squall Event|\n",
    "|After COVID_19(Jun 2020 to Dec 2020)|2020-06-06|Cold Front and Afternoon Thunderstorms|\n",
    "||2020-07-10 |Tropical Storm Fay|\n",
    "||2020-08-04|Tropical Storm Isaias|\n",
    "||2020-08-27|EF-1 Tornadoes and Severe Weather|\n",
    "||2020-12-16|Winter Storm|\n",
    "||2020-12-17|Winter Storm|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e0c84a92-31e4-4530-ae15-9fc8d8da00bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlopen\n",
    "from requests import get\n",
    "from urllib.parse import urlparse\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import numpy as np\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, validation_curve\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "import joblib\n",
    "\n",
    "# pipeline\n",
    "#from sklearn.pipeline import Pipeline\n",
    "# linear regression\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "# CART\n",
    "#from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# feature importance\n",
    "import rfpimp\n",
    "\n",
    "\n",
    "# xgboost\n",
    "import xgboost\n",
    "from xgboost import XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4dbc4006-fa4e-4a3c-b4f4-84ba270464ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the total loss, bias, and variance\n",
    "# !pip install mlxtend==0.21.0\n",
    "from mlxtend.evaluate import bias_variance_decomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "39df52ef-88db-4bce-a487-9ae99a3866c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost version:2.0.0\n",
      "sklearn version:1.3.0\n"
     ]
    }
   ],
   "source": [
    "# check the library version before we start\n",
    "print(\"xgboost version:{}\".format(xgboost.__version__))\n",
    "print(\"sklearn version:{}\".format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b5eba1a5-3391-46f2-9662-8bd0a8e6a12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4a9b5eea-c21a-4f67-b7c9-b0618de850c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.1 load the original data completed, continuing execution with the following code.\n"
     ]
    }
   ],
   "source": [
    "# 4.1 Load the original data\n",
    "# trip data before Covid-19\n",
    "# time range: from September 2019 to February 2020 \n",
    "# There is 16 csv files \n",
    "if False: \n",
    "    Before_bike = pd.DataFrame()  \n",
    "    folder_path = \"data/Before/\"  \n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.csv'):\n",
    "            ile_path = os.path.join(folder_path, file_name)  \n",
    "            df = pd.read_csv(file_path)  \n",
    "            Before_bike = pd.concat([Before_bike, df], ignore_index=True) \n",
    "    #check the dataframe\n",
    "    Before_bike #There is 11703041 trip data\n",
    "    Before_bike.drop(columns=['start station name', 'start station latitude','start station longitude','end station id','end station name','end station latitude','end station longitude','bikeid','birth year'], inplace=True)\n",
    "    # export the before data\n",
    "    Before_bike.to_csv(\"Before_bike.csv\", index=False)\n",
    "# trip data after Covid-19\n",
    "# time range: from June 2020 to December 2020\n",
    "# There is 18 csv files \n",
    "if False: \n",
    "    After_bike = pd.DataFrame()  \n",
    "    folder_path_1 = \"data/After/\"\n",
    "    for file_name in os.listdir(folder_path_1):\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path_1, file_name)  \n",
    "            df = pd.read_csv(file_path) \n",
    "            After_bike = pd.concat([After_bike, df], ignore_index=True) \n",
    "    #check the dataframe\n",
    "    After_bike # There is 13880322 trip data\n",
    "    After_bike.drop(columns=['start station name', 'start station latitude','start station longitude','end station id','end station name','end station latitude','end station longitude','bikeid','birth year'], inplace=True)\n",
    "    # export the after data\n",
    "    After_bike.to_csv(\"After_bike.csv\", index=False)\n",
    "print(\"4.1 load the original data completed, continuing execution with the following code.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e200f4da-6b8e-44e1-85d0-bcdf16539315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2 Merge and calcualtion completed, continuing execution with the following code.\n"
     ]
    }
   ],
   "source": [
    "# 4.2 Merge the data by the date and calculate the variables\n",
    "# before\n",
    "if False:\n",
    "    # read the before data\n",
    "    Before = pd.read_csv(\"Before_bike.csv\")\n",
    "    # data preprocessing \n",
    "    # Trip duration\n",
    "    # Change units from seconds to minutes\n",
    "    Before['tripduration_minutes'] = Before['tripduration'] / 60\n",
    "    # Create three categorical dummy variables \n",
    "    Before['duration_category'] = pd.cut(Before['tripduration_minutes'], bins=[0, 15, 30, np.inf], labels=['within_15min', '15-30mins', 'above30mins'])\n",
    "    Before = pd.get_dummies(Before, columns=['duration_category'])\n",
    "    # Uer types\n",
    "    # Create the dummy variable\n",
    "    Before = pd.get_dummies(Before, columns=['usertype'])\n",
    "    # gender\n",
    "    # delete the NaN value in Gender Column\n",
    "    Before = Before[Before['gender'] != 0] #results: has 9,714,849 rows\n",
    "    # Create the dummy variable\n",
    "    Before['gender'] = Before['gender'].replace({1: 'Male', 2: 'Female'})\n",
    "    Before = pd.get_dummies(Before, columns=['gender'])\n",
    "    # Aggregate data by date\n",
    "    # set the data types of datetime variable\n",
    "    Before['date'] = pd.to_datetime(Before['starttime']).dt.date\n",
    "    # Aggregate the trip numbers by date\n",
    "    daily_Before = Before.groupby('date').agg(\n",
    "        total_trips=('tripduration_minutes', 'count'),  # Daily total trips\n",
    "        trips_within_15min=('duration_category_within_15min', 'sum'),  # The daily trip number within 15 minutes\n",
    "        trips_15_to_30min=('duration_category_15-30mins', 'sum'),  # The daily trip number between 15 to 30 minutes\n",
    "        trips_above30min=('duration_category_above30mins', 'sum'),  # The daily trip number above 30 minutes\n",
    "        Customer_trips=('usertype_Customer', 'sum'),  # Daily trip number of customers \n",
    "        Subscriber_trips=('usertype_Subscriber', 'sum'),  # Daily trip number of subscriber\n",
    "        Female_trips=('gender_Female', 'sum')  # Daily trip number of female\n",
    "    )\n",
    "    # Calculate the proportion of each variable in total daily trips\n",
    "    daily_Before['percentage_within_15min'] = daily_Before['trips_within_15min'] / daily_Before['total_trips']\n",
    "    daily_Before['percentage_15_to_30min'] = daily_Before['trips_15_to_30min'] / daily_Before['total_trips']\n",
    "    daily_Before['percentage_above30min'] = daily_Before['trips_above30min'] / daily_Before['total_trips']\n",
    "    daily_Before['percentage_Customer'] = daily_Before['Customer_trips'] / daily_Before['total_trips']\n",
    "    daily_Before['percentage_Subscriber'] = daily_Before['Subscriber_trips'] / daily_Before['total_trips']\n",
    "    daily_Before['percentage_Female'] = daily_Before['Female_trips'] / daily_Before['total_trips']\n",
    "    daily_Before['percentage_Male'] = 1 - daily_Before['Female_trips'] / daily_Before['total_trips']\n",
    "    # create the new dataframe\n",
    "    daily_Before_pre = daily_Before[[\n",
    "    'total_trips',\n",
    "    'percentage_within_15min','percentage_15_to_30min','percentage_above30min',\n",
    "        'percentage_Customer','percentage_Subscriber',\n",
    "        'percentage_Female','percentage_Male']]\n",
    "    # reset the index\n",
    "    daily_Before_pre.reset_index(inplace=True)\n",
    "    # export the before data\n",
    "    daily_Before_pre.to_csv(\"before_pre.csv\",index=False)\n",
    "\n",
    "# After\n",
    "if False: \n",
    "    # read the after data\n",
    "    After = pd.read_csv(\"After_bike.csv\")\n",
    "    # data preprocessing \n",
    "    # Trip duration\n",
    "    # Change units from seconds to minutes\n",
    "    After['tripduration_minutes'] = After['tripduration'] / 60\n",
    "    # Create three categorical dummy variables \n",
    "    After['duration_category'] = pd.cut(After['tripduration_minutes'], bins=[0, 15, 30, np.inf], labels=['within_15min', '15-30mins', 'above30mins'])\n",
    "    After = pd.get_dummies(After, columns=['duration_category'])\n",
    "    # Uer types\n",
    "    # Create the dummy variable\n",
    "    After = pd.get_dummies(After, columns=['usertype'])\n",
    "    # gender\n",
    "    # delete the NaN value in Gender Column\n",
    "    After = After[After['gender'] != 0] #results: has 12,207,549 rows\n",
    "    # Create the dummy variable\n",
    "    After['gender'] = After['gender'].replace({1: 'Male', 2: 'Female'})\n",
    "    After = pd.get_dummies(After, columns=['gender'])\n",
    "    # Aggregate data by date\n",
    "    # set the data types of datetime variable\n",
    "    After['date'] = pd.to_datetime(After['starttime']).dt.date\n",
    "    # Aggregate the trip numbers by date\n",
    "    daily_After = After.groupby('date').agg(\n",
    "        total_trips=('tripduration_minutes', 'count'),  # daily total trips\n",
    "        trips_within_15min=('duration_category_within_15min', 'sum'),  # The daily trip number within 15 minutes\n",
    "        trips_15_to_30min=('duration_category_15-30mins', 'sum'),  # The daily trip number between 15 to 30 minutes\n",
    "        trips_above30min=('duration_category_above30mins', 'sum'),  # The daily trip number above 30 minutes\n",
    "        Customer_trips=('usertype_Customer', 'sum'),  # Daily trip number of customers \n",
    "        Subscriber_trips=('usertype_Subscriber', 'sum'),  # Daily trip number of subscriber\n",
    "        Female_trips=('gender_Female', 'sum') # Daily trip number of female\n",
    "    )\n",
    "    # Calculate the proportion of each variable in total daily trips\n",
    "    daily_After['percentage_within_15min'] = daily_After['trips_within_15min'] / daily_After['total_trips']\n",
    "    daily_After['percentage_15_to_30min'] = daily_After['trips_15_to_30min'] / daily_After['total_trips']\n",
    "    daily_After['percentage_above30min'] = daily_After['trips_above30min'] / daily_After['total_trips']\n",
    "    daily_After['percentage_Customer'] = daily_After['Customer_trips'] / daily_After['total_trips']\n",
    "    daily_After['percentage_Subscriber'] = daily_After['Subscriber_trips'] / daily_After['total_trips']\n",
    "    daily_After['percentage_Female'] = daily_After['Female_trips'] / daily_After['total_trips']\n",
    "    daily_After['percentage_Male'] = 1 - daily_After['Female_trips'] / daily_After['total_trips']\n",
    "    # create the new dataframe\n",
    "    daily_After_pre = daily_After[[\n",
    "        'total_trips',\n",
    "        'percentage_within_15min','percentage_15_to_30min','percentage_above30min',\n",
    "        'percentage_Customer','percentage_Subscriber',\n",
    "        'percentage_Female','percentage_Male']]\n",
    "    # reset the index\n",
    "    daily_After_pre.reset_index(inplace=True)\n",
    "    # export the after data\n",
    "    daily_After_pre.to_csv(\"after_pre.csv\", index=False) \n",
    "print(\"4.2 Merge and calcualtion completed, continuing execution with the following code.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "16c7b4ab-3014-4aa8-bfb6-58c0d3070a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>total_trips</th>\n",
       "      <th>percentage_within_15min</th>\n",
       "      <th>percentage_15_to_30min</th>\n",
       "      <th>percentage_above30min</th>\n",
       "      <th>percentage_Customer</th>\n",
       "      <th>percentage_Subscriber</th>\n",
       "      <th>percentage_Female</th>\n",
       "      <th>percentage_Male</th>\n",
       "      <th>Avg_temperature (F)</th>\n",
       "      <th>Heat</th>\n",
       "      <th>Cool</th>\n",
       "      <th>Weather Type</th>\n",
       "      <th>TLC_Precipitation (in)</th>\n",
       "      <th>Avg_Speed_Wind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>82156</td>\n",
       "      <td>0.695470</td>\n",
       "      <td>0.234213</td>\n",
       "      <td>0.070317</td>\n",
       "      <td>0.080846</td>\n",
       "      <td>0.919154</td>\n",
       "      <td>0.259871</td>\n",
       "      <td>0.740129</td>\n",
       "      <td>79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>BR</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>75731</td>\n",
       "      <td>0.681702</td>\n",
       "      <td>0.243229</td>\n",
       "      <td>0.075068</td>\n",
       "      <td>0.097939</td>\n",
       "      <td>0.902061</td>\n",
       "      <td>0.266337</td>\n",
       "      <td>0.733663</td>\n",
       "      <td>79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  total_trips  percentage_within_15min  percentage_15_to_30min  \\\n",
       "0 2019-08-01        82156                 0.695470                0.234213   \n",
       "1 2019-08-02        75731                 0.681702                0.243229   \n",
       "\n",
       "   percentage_above30min  percentage_Customer  percentage_Subscriber  \\\n",
       "0               0.070317             0.080846               0.919154   \n",
       "1               0.075068             0.097939               0.902061   \n",
       "\n",
       "   percentage_Female  percentage_Male  Avg_temperature (F)  Heat  Cool   \\\n",
       "0           0.259871         0.740129                   79   0.0   14.0   \n",
       "1           0.266337         0.733663                   79   0.0   14.0   \n",
       "\n",
       "  Weather Type TLC_Precipitation (in) Avg_Speed_Wind  \n",
       "0          BR                       0            2.2  \n",
       "1          NaN                      0            3.5  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.3 Reload the data\n",
    "Daily_Before = pd.read_csv(\"before_pre.csv\")\n",
    "Daily_After = pd.read_csv(\"after_pre.csv\")\n",
    "Climate = pd.read_csv(\"climate.csv\") \n",
    "\n",
    "# change the date type\n",
    "Daily_Before ['date'] = pd.to_datetime(Daily_Before ['date'])\n",
    "Daily_After ['date'] = pd.to_datetime(Daily_After ['date'])\n",
    "Climate['date'] = pd.to_datetime(Climate['date'])\n",
    "\n",
    "# merge the data\n",
    "Before = Daily_Before.merge(Climate,how='left', on='date')\n",
    "After = Daily_After.merge(Climate,how='left', on='date')\n",
    "# check the data\n",
    "Before.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b9ca9519-9fe2-470d-b5f5-442b9702efa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>total_trips</th>\n",
       "      <th>percentage_within_15min</th>\n",
       "      <th>percentage_15_to_30min</th>\n",
       "      <th>percentage_above30min</th>\n",
       "      <th>percentage_Customer</th>\n",
       "      <th>percentage_Subscriber</th>\n",
       "      <th>percentage_Female</th>\n",
       "      <th>percentage_Male</th>\n",
       "      <th>Avg_temperature (F)</th>\n",
       "      <th>Heat</th>\n",
       "      <th>Cool</th>\n",
       "      <th>Weather Type</th>\n",
       "      <th>TLC_Precipitation (in)</th>\n",
       "      <th>Avg_Speed_Wind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>46138</td>\n",
       "      <td>0.470458</td>\n",
       "      <td>0.321080</td>\n",
       "      <td>0.208462</td>\n",
       "      <td>0.191729</td>\n",
       "      <td>0.808271</td>\n",
       "      <td>0.341974</td>\n",
       "      <td>0.658026</td>\n",
       "      <td>61</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-02</td>\n",
       "      <td>40581</td>\n",
       "      <td>0.453168</td>\n",
       "      <td>0.327912</td>\n",
       "      <td>0.218920</td>\n",
       "      <td>0.179246</td>\n",
       "      <td>0.820754</td>\n",
       "      <td>0.348217</td>\n",
       "      <td>0.651783</td>\n",
       "      <td>66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>RA</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  total_trips  percentage_within_15min  percentage_15_to_30min  \\\n",
       "0 2020-06-01        46138                 0.470458                0.321080   \n",
       "1 2020-06-02        40581                 0.453168                0.327912   \n",
       "\n",
       "   percentage_above30min  percentage_Customer  percentage_Subscriber  \\\n",
       "0               0.208462             0.191729               0.808271   \n",
       "1               0.218920             0.179246               0.820754   \n",
       "\n",
       "   percentage_Female  percentage_Male  Avg_temperature (F)  Heat  Cool   \\\n",
       "0           0.341974         0.658026                   61   4.0    0.0   \n",
       "1           0.348217         0.651783                   66   0.0    1.0   \n",
       "\n",
       "  Weather Type TLC_Precipitation (in) Avg_Speed_Wind  \n",
       "0          NaN                      0            NaN  \n",
       "1           RA                      T            NaN  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the data\n",
    "After.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c924a155-6344-417c-a183-a4446076d3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 183 entries, 0 to 182\n",
      "Data columns (total 15 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   date                     183 non-null    datetime64[ns]\n",
      " 1   total_trips              183 non-null    int64         \n",
      " 2   percentage_within_15min  183 non-null    float64       \n",
      " 3   percentage_15_to_30min   183 non-null    float64       \n",
      " 4   percentage_above30min    183 non-null    float64       \n",
      " 5   percentage_Customer      183 non-null    float64       \n",
      " 6   percentage_Subscriber    183 non-null    float64       \n",
      " 7   percentage_Female        183 non-null    float64       \n",
      " 8   percentage_Male          183 non-null    float64       \n",
      " 9   Avg_temperature (F)      183 non-null    int64         \n",
      " 10  Heat                     183 non-null    float64       \n",
      " 11  Cool                     183 non-null    float64       \n",
      " 12  Weather Type             82 non-null     object        \n",
      " 13  TLC_Precipitation (in)   183 non-null    object        \n",
      " 14  Avg_Speed_Wind           183 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(9), int64(2), object(3)\n",
      "memory usage: 21.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# check the data type\n",
    "Before.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "dee71aeb-8c26-49e7-a7bb-a1534750d032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 214 entries, 0 to 213\n",
      "Data columns (total 15 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   date                     214 non-null    datetime64[ns]\n",
      " 1   total_trips              214 non-null    int64         \n",
      " 2   percentage_within_15min  214 non-null    float64       \n",
      " 3   percentage_15_to_30min   214 non-null    float64       \n",
      " 4   percentage_above30min    214 non-null    float64       \n",
      " 5   percentage_Customer      214 non-null    float64       \n",
      " 6   percentage_Subscriber    214 non-null    float64       \n",
      " 7   percentage_Female        214 non-null    float64       \n",
      " 8   percentage_Male          214 non-null    float64       \n",
      " 9   Avg_temperature (F)      214 non-null    int64         \n",
      " 10  Heat                     214 non-null    float64       \n",
      " 11  Cool                     214 non-null    float64       \n",
      " 12  Weather Type             98 non-null     object        \n",
      " 13  TLC_Precipitation (in)   214 non-null    object        \n",
      " 14  Avg_Speed_Wind           196 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(9), int64(2), object(3)\n",
      "memory usage: 25.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# check the data type\n",
    "After.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5b08dc1f-84f1-4c0a-802e-0513d43e3c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "\n",
    "# Weather conditions\n",
    "# delete extreme climate\n",
    "# Before:  extreme climate （2019-12-18）\n",
    "Before = Before[Before['date'] != '2019-12-18']\n",
    "# After:  extreme climate （'2020-06-06', '2020-07-10','2020-08-04','2020-08-27','2020-12-16','2020-12-17')\n",
    "After = After [~After ['date'].isin(['2020-06-06', '2020-07-10','2020-08-04','2020-08-27','2020-12-16','2020-12-17'])]\n",
    "\n",
    "# TLC_Precipitation\n",
    "# Regarding 'TLC_Precipitation (in)', it has value T, which is a trace amount of precipitation. \n",
    "# A trace amount of precipitation means that the amount of precipitation is very small, almost negligible.\n",
    "# Thus, the value T is changed to 0\n",
    "# Before: \n",
    "Before['TLC_Precipitation (in)'] = Before['TLC_Precipitation (in)'].replace('T', 0)\n",
    "# After: \n",
    "After['TLC_Precipitation (in)'] = After['TLC_Precipitation (in)'].replace('T', 0)\n",
    "\n",
    "# Avg_Speed_Wind\n",
    "# 'Avg_Speed_Wind' has NaN value, drop it\n",
    "Before = Before[Before['Avg_Speed_Wind'] != 'na']\n",
    "After = After.dropna(subset=['Avg_Speed_Wind'])\n",
    "\n",
    "\n",
    "# Travel Pattern\n",
    "# increase day type variable weekday (1) weekend (0)\n",
    "# Before\n",
    "Before['weekday'] = Before['date'].dt.weekday\n",
    "Before['is_weekday'] = Before['weekday'].apply(lambda x: 1 if x < 5 else 0)\n",
    "Before = Before.drop('weekday', axis=1)\n",
    "# After\n",
    "After['weekday'] = After['date'].dt.weekday\n",
    "After['is_weekday'] = After['weekday'].apply(lambda x: 1 if x < 5 else 0)\n",
    "After = After.drop('weekday', axis=1)\n",
    "\n",
    "# drop the column\n",
    "# Before\n",
    "Before = Before.drop('Weather Type', axis=1)\n",
    "# After\n",
    "After = After.drop('Weather Type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e6422a70-7987-4cdf-9e9b-d601dc4b9257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                       0\n",
       "total_trips                0\n",
       "percentage_within_15min    0\n",
       "percentage_15_to_30min     0\n",
       "percentage_above30min      0\n",
       "percentage_Customer        0\n",
       "percentage_Subscriber      0\n",
       "percentage_Female          0\n",
       "percentage_Male            0\n",
       "Avg_temperature (F)        0\n",
       "Heat                       0\n",
       "Cool                       0\n",
       "TLC_Precipitation (in)     0\n",
       "Avg_Speed_Wind             0\n",
       "is_weekday                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check NaN value\n",
    "Before.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a1187713-c9b3-4f06-840b-68de5e6317b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                       0\n",
       "total_trips                0\n",
       "percentage_within_15min    0\n",
       "percentage_15_to_30min     0\n",
       "percentage_above30min      0\n",
       "percentage_Customer        0\n",
       "percentage_Subscriber      0\n",
       "percentage_Female          0\n",
       "percentage_Male            0\n",
       "Avg_temperature (F)        0\n",
       "Heat                       0\n",
       "Cool                       0\n",
       "TLC_Precipitation (in)     0\n",
       "Avg_Speed_Wind             0\n",
       "is_weekday                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check NaN value\n",
    "After.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d0394879-66c6-4319-beb2-537e73d36b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 177 entries, 0 to 182\n",
      "Data columns (total 15 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   date                     177 non-null    datetime64[ns]\n",
      " 1   total_trips              177 non-null    int64         \n",
      " 2   percentage_within_15min  177 non-null    float64       \n",
      " 3   percentage_15_to_30min   177 non-null    float64       \n",
      " 4   percentage_above30min    177 non-null    float64       \n",
      " 5   percentage_Customer      177 non-null    float64       \n",
      " 6   percentage_Subscriber    177 non-null    float64       \n",
      " 7   percentage_Female        177 non-null    float64       \n",
      " 8   percentage_Male          177 non-null    float64       \n",
      " 9   Avg_temperature (F)      177 non-null    int64         \n",
      " 10  Heat                     177 non-null    float64       \n",
      " 11  Cool                     177 non-null    float64       \n",
      " 12  TLC_Precipitation (in)   177 non-null    float64       \n",
      " 13  Avg_Speed_Wind           177 non-null    float64       \n",
      " 14  is_weekday               177 non-null    int64         \n",
      "dtypes: datetime64[ns](1), float64(11), int64(3)\n",
      "memory usage: 22.1 KB\n"
     ]
    }
   ],
   "source": [
    "Before['TLC_Precipitation (in)'] = Before['TLC_Precipitation (in)'].astype(float)\n",
    "Before['Avg_Speed_Wind'] = Before['Avg_Speed_Wind'].astype(float)\n",
    "# check the data type\n",
    "Before.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "979955d0-cf98-401e-a2d2-be24ad928a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 191 entries, 18 to 213\n",
      "Data columns (total 15 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   date                     191 non-null    datetime64[ns]\n",
      " 1   total_trips              191 non-null    int64         \n",
      " 2   percentage_within_15min  191 non-null    float64       \n",
      " 3   percentage_15_to_30min   191 non-null    float64       \n",
      " 4   percentage_above30min    191 non-null    float64       \n",
      " 5   percentage_Customer      191 non-null    float64       \n",
      " 6   percentage_Subscriber    191 non-null    float64       \n",
      " 7   percentage_Female        191 non-null    float64       \n",
      " 8   percentage_Male          191 non-null    float64       \n",
      " 9   Avg_temperature (F)      191 non-null    int64         \n",
      " 10  Heat                     191 non-null    float64       \n",
      " 11  Cool                     191 non-null    float64       \n",
      " 12  TLC_Precipitation (in)   191 non-null    float64       \n",
      " 13  Avg_Speed_Wind           191 non-null    float64       \n",
      " 14  is_weekday               191 non-null    int64         \n",
      "dtypes: datetime64[ns](1), float64(11), int64(3)\n",
      "memory usage: 23.9 KB\n"
     ]
    }
   ],
   "source": [
    "After['TLC_Precipitation (in)'] = After['TLC_Precipitation (in)'].astype(float)\n",
    "After['Avg_Speed_Wind'] = After['Avg_Speed_Wind'].astype(float)\n",
    "# check the data type\n",
    "After.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5dc0d90b-820b-4151-bdf4-31b0f7ca2961",
   "metadata": {},
   "source": [
    "## 5. METHODOLOGY\n",
    "\n",
    "**R Square**:\n",
    "\n",
    "\\begin{equation} \\tag{1}\n",
    " R^2 = 1 - \\frac{{\\sum_{i=1}^{n} (\\hat{y}_i - \\bar{y})^2}}{{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}} \n",
    "\\end{equation}\n",
    "\n",
    "**RMSE**:\n",
    "\\begin{equation} \\tag{2}\n",
    "RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}\n",
    "\\end{equation}\n",
    "\n",
    "Where   \n",
    "$\\hat{y}_i$ is the predicted value of target variable for $i$ th sample;  \n",
    "$\\bar{y}$ is  the mean of the target variable;  \n",
    "$y_{i}$ is the observed actual values of the target variable for $i$ th sample;   \n",
    "$ n $ is the number of samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e03d8d-89d2-480d-9ac1-56b67707edc0",
   "metadata": {},
   "source": [
    "### 5.1 Training Models & Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "92531e55-d142-44ca-8b1e-00881611ae69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 13)\n",
      "(132,)\n",
      "(45, 13)\n",
      "(45,)\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# split train (75%) and test (25%)\n",
    "# before\n",
    "Before_nodate = Before.drop('date', axis=1)\n",
    "random_state_split = 100\n",
    "train_x_B, test_x_B, train_y_B, test_y_B = train_test_split(Before_nodate.drop(['total_trips'], axis = 1), Before_nodate.total_trips, random_state=random_state_split)\n",
    "# check the shape\n",
    "print(train_x_B.shape)\n",
    "print(train_y_B.shape)\n",
    "print(test_x_B.shape)\n",
    "print(test_y_B.shape)\n",
    "\n",
    "# check the index of train_x and train_y - they should be identical. The index indicates which rows from the original data.\n",
    "print(train_x_B.index.identical(train_y_B.index))\n",
    "print(test_x_B.index.identical(test_y_B.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ad47f861-b048-4dea-a59b-960a29deaef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(143, 13)\n",
      "(143,)\n",
      "(48, 13)\n",
      "(48,)\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# split train (75%) and test (25%)\n",
    "# after\n",
    "After_nodate = After.drop('date', axis=1)\n",
    "random_state_split = 100\n",
    "train_x_A, test_x_A, train_y_A, test_y_A = train_test_split(After_nodate.drop(['total_trips'], axis = 1), After_nodate.total_trips, random_state=random_state_split)\n",
    "# check the shape\n",
    "print(train_x_A.shape)\n",
    "print(train_y_A.shape)\n",
    "print(test_x_A.shape)\n",
    "print(test_y_A.shape)\n",
    "\n",
    "# check the index of train_x and train_y - they should be identical. The index indicates which rows from the original data.\n",
    "\n",
    "print(train_x_A.index.identical(train_y_A.index))\n",
    "print(test_x_A.index.identical(test_y_A.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dc030e-c9cc-473f-900c-3268afd5beb8",
   "metadata": {},
   "source": [
    "#### (a) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1970cbf0-b9cf-4100-b8f4-5443f65fb75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameter value is: \n",
      "{'max_depth': 10, 'min_samples_split': 2}\n",
      "The best score is: \n",
      "0.8301190849302813\n"
     ]
    }
   ],
   "source": [
    "# Before: Random Forest\n",
    "# values of max_depth and min_samples_split\n",
    "hyperparameters = {'max_depth':[10,20,30,40,50], 'min_samples_split':[2,4,6,8,10]}\n",
    "\n",
    "randomState_dt = 10000\n",
    "rf = RandomForestRegressor(random_state=randomState_dt)\n",
    "\n",
    "# cv=5 by default, which means 10-fold cross-validation\n",
    "RFB = GridSearchCV(rf, hyperparameters,cv=10)\n",
    "\n",
    "RFB.fit(train_x_B, train_y_B)\n",
    "\n",
    "# we can query the best parameter value and its accuracy score\n",
    "print (\"The best parameter value is: \")\n",
    "print (RFB.best_params_)\n",
    "print (\"The best score is: \")\n",
    "print (RFB.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "19766b95-544d-4cd6-9fca-63cab8908ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=10, random_state=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=10, random_state=10000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=10, random_state=10000)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFB_final = RandomForestRegressor(max_depth=RFB.best_params_['max_depth'], min_samples_split=RFB.best_params_['min_samples_split'], random_state=randomState_dt)\n",
    "RFB_final.fit(train_x_B, train_y_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6bf7a343-23dc-4313-9633-655e819f295c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on the training data:\n",
      "0.9811900865580362\n",
      "R2 on the testing data:\n",
      "0.697243462907573\n"
     ]
    }
   ],
   "source": [
    "print(\"R2 on the training data:\")\n",
    "print(RFB_final.score(X=train_x_B, y=train_y_B))\n",
    "print(\"R2 on the testing data:\")\n",
    "print(RFB_final.score(X=test_x_B, y=test_y_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9b5ff448-9ac8-412f-969c-e7c3819432e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the training data:\n",
      "2849.2044456162184\n",
      "RMSE on the testing data:\n",
      "11493.74314860294\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE on the training data:\")\n",
    "print(mean_squared_error(train_y_B, RFB_final.predict(train_x_B), squared=False))\n",
    "print(\"RMSE on the testing data:\")\n",
    "print(mean_squared_error(test_y_B, RFB_final.predict(test_x_B), squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c513f20b-1305-4522-bcda-b23572ca29f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameter value is: \n",
      "{'max_depth': 20, 'min_samples_split': 4}\n",
      "The best score is: \n",
      "0.7650354040945333\n"
     ]
    }
   ],
   "source": [
    "# After: random Forest\n",
    "# values of max_depth and min_samples_split\n",
    "hyperparameters = {'max_depth':[10,20,30,40,50], 'min_samples_split':[2,4,6,8,10]}\n",
    "\n",
    "randomState_dt = 10000\n",
    "rf = RandomForestRegressor(random_state=randomState_dt)\n",
    "\n",
    "# cv=5 by default, which means 10-fold cross-validation\n",
    "RFA = GridSearchCV(rf, hyperparameters,cv=10)\n",
    "\n",
    "RFA.fit(train_x_A, train_y_A)\n",
    "\n",
    "# we can query the best parameter value and its accuracy score\n",
    "print (\"The best parameter value is: \")\n",
    "print (RFA.best_params_)\n",
    "print (\"The best score is: \")\n",
    "print (RFA.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5f6d0ef5-17b6-4966-aa6a-45b51a2f123f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=20, min_samples_split=4, random_state=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=20, min_samples_split=4, random_state=10000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=20, min_samples_split=4, random_state=10000)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFA_final = RandomForestRegressor(max_depth=RFA.best_params_['max_depth'], min_samples_split=RFA.best_params_['min_samples_split'], random_state=randomState_dt)\n",
    "RFA_final.fit(train_x_A, train_y_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9cbb6b48-69d6-492b-b89b-04679c546e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on the training data:\n",
      "0.9672266779772797\n",
      "R2 on the testing data:\n",
      "0.7996831410518246\n"
     ]
    }
   ],
   "source": [
    "print(\"R2 on the training data:\")\n",
    "print(RFA_final.score(X=train_x_A, y=train_y_A))\n",
    "print(\"R2 on the testing data:\")\n",
    "print(RFA_final.score(X=test_x_A, y=test_y_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5605949f-fb82-460e-85cd-887ba729ffb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the training data:\n",
      "3080.182587685826\n",
      "RMSE on the testing data:\n",
      "7725.544704978764\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE on the training data:\")\n",
    "print(mean_squared_error(train_y_A, RFA_final.predict(train_x_A), squared=False))\n",
    "print(\"RMSE on the testing data:\")\n",
    "print(mean_squared_error(test_y_A, RFA_final.predict(test_x_A), squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21d8c55-17a4-44a1-aeb1-3d71466c611b",
   "metadata": {},
   "source": [
    "####  (b) XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "daa74724-ec6c-4c20-b176-e018c3dcb8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "# values of max_depth and min_samples_split\n",
    "hyperparameters = {'max_depth':[10,20,30,40,50], 'n_estimators':[50,100,150,200,250]}\n",
    "\n",
    "randomState_xgb = 125\n",
    "xgb = XGBRegressor(random_state=randomState_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2448b1e3-42a8-423d-a74f-8eee27a4be84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameter value is: \n",
      "{'max_depth': 30, 'n_estimators': 250}\n",
      "The best score is: \n",
      "0.7962290068459446\n"
     ]
    }
   ],
   "source": [
    "#Before\n",
    "# cv=5 by default, which means 10-fold cross-validation\n",
    "gscv_xgb_B = GridSearchCV(xgb, hyperparameters,cv=10)\n",
    "\n",
    "gscv_xgb_B.fit(train_x_B, train_y_B)\n",
    "\n",
    "# we can query the best parameter value and its accuracy score\n",
    "print (\"The best parameter value is: \")\n",
    "print (gscv_xgb_B.best_params_)\n",
    "print (\"The best score is: \")\n",
    "print (gscv_xgb_B.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e8fb8da0-30af-4a6b-8a87-6b9932b9c0e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=30, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=250, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=125, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=30, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=250, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=125, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=30, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=250, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=125, ...)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_final_B = XGBRegressor(max_depth=gscv_xgb_B.best_params_['max_depth'], n_estimators=gscv_xgb_B.best_params_['n_estimators'], random_state=randomState_xgb)\n",
    "xgb_final_B.fit(train_x_B, train_y_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "462c911f-686c-43e3-9588-8de955c36a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on the training data:\n",
      "0.9999999999998798\n",
      "R2 on the testing data:\n",
      "0.713737419482992\n"
     ]
    }
   ],
   "source": [
    "print(\"R2 on the training data:\")\n",
    "print(xgb_final_B.score(X=train_x_B, y=train_y_B))\n",
    "print(\"R2 on the testing data:\")\n",
    "print(xgb_final_B.score(X=test_x_B, y=test_y_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "1944c3f4-d4aa-4f50-8bbd-5a59650fa1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the training data:\n",
      "0.007202869412503982\n",
      "RMSE on the testing data:\n",
      "11176.273320050354\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE on the training data:\")\n",
    "print(mean_squared_error(train_y_B, xgb_final_B.predict(train_x_B), squared=False))\n",
    "print(\"RMSE on the testing data:\")\n",
    "print(mean_squared_error(test_y_B, xgb_final_B.predict(test_x_B), squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ac5e2820-6bef-48c9-9bb7-d6293a17d1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameter value is: \n",
      "{'max_depth': 10, 'n_estimators': 250}\n",
      "The best score is: \n",
      "0.7329714866802057\n"
     ]
    }
   ],
   "source": [
    "# After \n",
    "# cv=5 by default, which means 10-fold cross-validation\n",
    "gscv_xgb_A = GridSearchCV(xgb, hyperparameters,cv=10)\n",
    "gscv_xgb_A.fit(train_x_A, train_y_A)\n",
    "# we can query the best parameter value and its accuracy score\n",
    "print (\"The best parameter value is: \")\n",
    "print (gscv_xgb_A.best_params_)\n",
    "print (\"The best score is: \")\n",
    "print (gscv_xgb_A.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c200dbe4-d874-44b6-bc54-a00b73fc141b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=250, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=125, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=250, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=125, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=250, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=125, ...)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_final_A = XGBRegressor(max_depth=gscv_xgb_A.best_params_['max_depth'], n_estimators=gscv_xgb_A.best_params_['n_estimators'], random_state=randomState_xgb)\n",
    "xgb_final_A.fit(train_x_A, train_y_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "23075006-558a-4b03-ba3a-b2390dd53864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on the training data:\n",
      "0.9999999999997922\n",
      "R2 on the testing data:\n",
      "0.7322546889820232\n"
     ]
    }
   ],
   "source": [
    "print(\"R2 on the training data:\")\n",
    "print(xgb_final_A.score(X=train_x_A, y=train_y_A))\n",
    "print(\"R2 on the testing data:\")\n",
    "print(xgb_final_A.score(X=test_x_A, y=test_y_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5d60cc87-9e94-4605-8f60-09b1c2b4c84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the training data:\n",
      "0.0077563851469326815\n",
      "RMSE on the testing data:\n",
      "8931.641769680038\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE on the training data:\")\n",
    "print(mean_squared_error(train_y_A, xgb_final_A.predict(train_x_A), squared=False))\n",
    "print(\"RMSE on the testing data:\")\n",
    "print(mean_squared_error(test_y_A, xgb_final_A.predict(test_x_A), squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe17cc04-4e8d-4de5-9d8b-19d652e08da7",
   "metadata": {},
   "source": [
    "### 5.2 Assessing Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d23360df-460d-468b-b462-bc7b78a52b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train R²</th>\n",
       "      <th>Test R²</th>\n",
       "      <th>R² Difference</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>RMSE Difference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest(before)</th>\n",
       "      <td>0.981190</td>\n",
       "      <td>0.697243</td>\n",
       "      <td>-0.283947</td>\n",
       "      <td>2849.204446</td>\n",
       "      <td>11493.743149</td>\n",
       "      <td>8644.538703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest(after)</th>\n",
       "      <td>0.967227</td>\n",
       "      <td>0.799683</td>\n",
       "      <td>-0.167544</td>\n",
       "      <td>3080.182588</td>\n",
       "      <td>7725.544705</td>\n",
       "      <td>4645.362117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost(before)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.713737</td>\n",
       "      <td>-0.286263</td>\n",
       "      <td>0.007203</td>\n",
       "      <td>11176.273320</td>\n",
       "      <td>11176.266117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost(after)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.732255</td>\n",
       "      <td>-0.267745</td>\n",
       "      <td>0.007756</td>\n",
       "      <td>8931.641770</td>\n",
       "      <td>8931.634013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Train R²   Test R²  R² Difference   Train RMSE  \\\n",
       "Model                                                                   \n",
       "Random Forest(before)  0.981190  0.697243      -0.283947  2849.204446   \n",
       "Random Forest(after)   0.967227  0.799683      -0.167544  3080.182588   \n",
       "XGBoost(before)        1.000000  0.713737      -0.286263     0.007203   \n",
       "XGBoost(after)         1.000000  0.732255      -0.267745     0.007756   \n",
       "\n",
       "                          Test RMSE  RMSE Difference  \n",
       "Model                                                 \n",
       "Random Forest(before)  11493.743149      8644.538703  \n",
       "Random Forest(after)    7725.544705      4645.362117  \n",
       "XGBoost(before)        11176.273320     11176.266117  \n",
       "XGBoost(after)          8931.641770      8931.634013  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the  R² and RMSE for each model\n",
    "def calculate_metrics(model, test_x, test_y, train_x, train_y):\n",
    "    r2_train = model.score(train_x, train_y)\n",
    "    rmse_train = mean_squared_error(train_y,model.predict(train_x), squared=False)\n",
    "    r2_test = model.score(test_x, test_y)\n",
    "    rmse_test = mean_squared_error(test_y,model.predict(test_x), squared=False)\n",
    "    return r2_test, rmse_test, r2_train, rmse_train\n",
    "\n",
    "# create a table\n",
    "results = []\n",
    "\n",
    "\n",
    "for model_name, model, test_x, test_y, train_x, train_y in [(\"Random Forest(before)\", RFB_final, test_x_B, test_y_B, train_x_B, train_y_B), \n",
    "                                                            (\"Random Forest(after)\", RFA_final, test_x_A, test_y_A, train_x_A, train_y_A), \n",
    "                                                            (\"XGBoost(before)\", xgb_final_B, test_x_B, test_y_B, train_x_B, train_y_B), \n",
    "                                                            (\"XGBoost(after)\", xgb_final_A, test_x_A, test_y_A, train_x_A, train_y_A)]:\n",
    "    # calculate the indicators\n",
    "    r2_test, rmse_test, r2_train, rmse_train = calculate_metrics(model, test_x, test_y, train_x, train_y)\n",
    "    # calculate the differences between train and test set\n",
    "    r2_diff = r2_test - r2_train\n",
    "    rmse_diff = rmse_test - rmse_train\n",
    "    # back to the table\n",
    "    results.append([model_name,r2_train,r2_test,r2_diff,rmse_train,rmse_test,rmse_diff])\n",
    "\n",
    "# create dataframe\n",
    "model_results = pd.DataFrame(results, columns=[\"Model\",\"Train R²\", \"Test R²\", \"R² Difference\",\"Train RMSE\",\"Test RMSE\",\"RMSE Difference\"])\n",
    "model_results.set_index(\"Model\", inplace=True)\n",
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ea1f17a4-6216-4575-bee1-bfe06e981340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total loss</th>\n",
       "      <th>Bias (or Bias^2)</th>\n",
       "      <th>Variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RF_A</th>\n",
       "      <td>7.170107e+07</td>\n",
       "      <td>6.108105e+07</td>\n",
       "      <td>1.062002e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB_A</th>\n",
       "      <td>7.842480e+07</td>\n",
       "      <td>5.693896e+07</td>\n",
       "      <td>2.148584e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_B</th>\n",
       "      <td>1.416843e+08</td>\n",
       "      <td>1.288284e+08</td>\n",
       "      <td>1.285590e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB_B</th>\n",
       "      <td>1.392089e+08</td>\n",
       "      <td>1.074192e+08</td>\n",
       "      <td>3.178965e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Total loss  Bias (or Bias^2)      Variance\n",
       "RF_A   7.170107e+07      6.108105e+07  1.062002e+07\n",
       "XGB_A  7.842480e+07      5.693896e+07  2.148584e+07\n",
       "RF_B   1.416843e+08      1.288284e+08  1.285590e+07\n",
       "XGB_B  1.392089e+08      1.074192e+08  3.178965e+07"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the Total loss,Bias (or Bias^2),and Variance for each model\n",
    "random_seed = 1233\n",
    "regressors = {\n",
    "    'RF_A': RandomForestRegressor(random_state=random_seed),\n",
    "    'XGB_A': XGBRegressor(random_state=random_seed),\n",
    "    'RF_B': RandomForestRegressor(random_state=random_seed),\n",
    "    'XGB_B': XGBRegressor(random_state=random_seed)\n",
    "}\n",
    "\n",
    "# a dict to store the R2 of training and testing data\n",
    "dict_results = dict()\n",
    "\n",
    "for name, regressor in regressors.items():\n",
    "    if 'RF' in name:\n",
    "        train_x = train_x_A if 'A' in name else train_x_B\n",
    "        train_y = train_y_A if 'A' in name else train_y_B\n",
    "        test_x = test_x_A if 'A' in name else test_x_B\n",
    "        test_y = test_y_A if 'A' in name else test_y_B\n",
    "    elif 'XGB' in name:\n",
    "        train_x = train_x_A if 'A' in name else train_x_B\n",
    "        train_y = train_y_A if 'A' in name else train_y_B\n",
    "        test_x = test_x_A if 'A' in name else test_x_B\n",
    "        test_y = test_y_A if 'A' in name else test_y_B\n",
    "        \n",
    "    avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        regressor, train_x.to_numpy(), train_y.to_numpy(), test_x.to_numpy(), test_y.to_numpy(), \n",
    "        loss='mse',\n",
    "        random_seed=123,\n",
    "        num_rounds=50)\n",
    "    dict_results[name] = [avg_expected_loss, avg_bias, avg_var]\n",
    "\n",
    "# transform dict_models to dataframe\n",
    "com_models = pd.DataFrame.from_dict(dict_results, orient='index', columns=['Total loss', 'Bias (or Bias^2)', 'Variance'])\n",
    "com_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801760b8-56a1-4e5e-9cb8-b4dbe4d91362",
   "metadata": {},
   "source": [
    "### 5.3 Analysing the Importance of Explanatory Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cab54c-dd49-49d8-91ff-46139173937d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69e0561-53d3-4808-a85e-5cc353eae994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff4ceefb-92bf-46d8-afd1-484efa71fc88",
   "metadata": {},
   "source": [
    "## 6. RESULTS\n",
    "\n",
    "1. Compare the performance of model\n",
    "\n",
    "2. the relative importance analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3b09a46-d96e-485e-95d8-81b162c25815",
   "metadata": {},
   "source": [
    "## 7. DISCUSSION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c38cfc45-a56c-46a2-a8a7-019da7703e87",
   "metadata": {},
   "source": [
    "## 8. CONCLUSION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd8e46a1-ff7c-4b22-9c0f-10c8218e8d18",
   "metadata": {},
   "source": [
    "## REFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456afaba-1026-4aa2-9194-a1fa50d42249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
